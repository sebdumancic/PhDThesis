\chapter{Learning with logic}\label{ch:learninglogic}



This chapter briefly introduces the concepts of relational learning.
It starts with a short introduction to logic, starting from a propositional logic and gradually climbs the ladder of complexity all the way to the logic programming.
It continues with a brief introduction to Inductive logic programming.
Finally, it touches upon a contemporary topic of \textit{Probabilistic} Inductive Logic Programming which combines Inductive Logic Programming  with probability theory in order to quantify uncertainty of the reasoning.




\section{Representing data with logic}





\subsection{Propositional logic}

Propositional logic is a formalism for reasoning about the truth assignments of \textit{propositions}.
Propositions are statements about the world being modelled, and can be \textit{true} or \textit{false}.


The propositions are constructed from propositional \textit{variables} and \textit{connectivity operators}.
Propositional variables denote \textit{aspects} of the world considered by the model, for instance, \texttt{sun}, \texttt{rainbow} and \texttt{bob\_runs}.
Variables are used in propositions as \textit{literals} -- a propositional variable or its negation.
The connectivity operators compose literals into more complicated statements.
Such operators in \textit{conjunction} (AND operator), \textit{disjunction} (OR operator), \textit{implication} (IF-THEN operator) and \textit{equivalence} (IF-AND-ONLY-IF	operator).


A \textit{logical theory} is a collection of propositions, more precisely, a conjunction of propositions.
An \textit{interpretation} is a truth assignment for each of the propositional variables.
An interpretation satisfies a given proposition if it evaluates to \textit{true} for the given truth assignments to the variables.
An interpretation that satisfies the proposition is a \textit{model} of that proposition.



\paragraph{Example} The proposition 
$$\text{\textit{playful}} \wedge \text{\textit{fluffy}} \Rightarrow \text{\textit{ideal\_pet}} $$
encodes that when something is playful (variable \textit{playful} is true) and fluffy (variable \textit{fluffy} is true )then it is an ideal pet (variable \textit{ideal\_pet} is true).
Every interpretation in which \textit{ideal\_pet} is true is a model of this proposition.




Once the theory describing the knowledge is available, different \textit{inference} tasks can be considered.
The most fundamental task is that of \textit{consistency} or \textit{satisfiability} checking, which checks whether the theory has a model.
The task of \textit{validity} checking checks whether every interpretation is a model.
The task of \textit{model counting}, a generalisation of both aforementioned tasks, counts the number of models of the theory.









\subsection{Predicate logic}


Propositional logic is suitable framework for drawing inferences about individual objects or examples (where each example is an interpretation), but encoding more complex knowledge in form of relations between objects is extremely tedious.
For instance, to indicate that two animals are of the same species would require introducing new boolean variables for each pair of animals, such as \textit{same\_species\_dog\_cat}, and specifying their truth assignments.



To over come this issue, \textit{predicate logic} extends the propositional logic with \textit{objects} and \textit{relations} between them, resulting in a powerful language for representing mathematical formalism.
An especially attractive feature of predicate logic is its universal \textit{inference algorithm} -- one can state a set of axioms, or facts, and theorems in predicate logic and rely on \textit{resolution} \cite{Robinson:1965:Resolution} inference algorithm to derive new axioms and theorems from the old ones.



The language of predicate logic is similar to the one of the propositional logic.
The core building blocks of predicate logic formulas are \textit{four} types of symbols: \textit{constant} (referring to individual objects), \textit{variable} (referring to groups of objects), \textit{function} and \textit{predicate} symbols.


The statements in predicate logic, the formulas, are composed of \textit{terms}, \textit{atoms} and \textit{connectivity operators}.
A \textit{term} is defined as:
\begin{itemize}
	\item a constant is a term
	\item a variable is a term
	\item if $f / n$ is a function symbol and $t_1,t_2,...,t_n$ are terms, then function $f(t_1,...,t_n)$ is a term.
\end{itemize}


An \textit{atom} is of the form $p(t_1,...,t_n)$ where $p/n$ is a predicate symbol and $t_1,...,t_n$ are terms.
A \textit{literal} is an atom or its negation.


Finally, a \textit{formula} in predicate logic is defined as:
\begin{itemize}
	\item An atom is a formula
	\item \texttt{true} and \texttt{false} are formulas
	\item If $\phi$ and $\psi$ are formulas, so are $\phi \wedge \psi$, $\phi \vee \psi$, $\phi \rightarrow \psi$, $\phi \leftrightarrow \psi$ and $\not \phi$
	\item If $\phi$ is a formula and $X$ is a variable, so are $\forall X \phi$ and $\exists X \phi$.
\end{itemize}


A \textit{literal} in predicate logic is an atom or its negation.
Formula is \textit{ground} if it does not contain logical variables, meaning that the variables are \textit{bind} to the exact objects or individuals.


 
 
 


Evaluating formulas in predicate logic is not as simple as in the propositional logic.
The main complication comes from the usage of variables.
Thus, in order to specify the interpretation one first has to, for each predicate,  map logical variables to a set of domain elements, i.e., each predicate has to be \textit{grounded}.
Once groundings are obtained, each grounding of a predicate is associated with \textit{true} or \textit{false}.



\paragraph{Example} Mapping the previous example in propositional logic to predicate logic results in the following formula: 

$$\forall X \quad \text{\textit{is\_playful(X)}} \wedge \text{\textit{is\_fluffy(X)}} \Rightarrow \text{\textit{ideal\_pet(X)}}. $$

 Predicate logic allows us to easily express more complex knowledge relating different objects.
 For instance, we can refine the previous formula and add a condition that an ideal pet also needs to have at least one friend: 
 $$\forall X, \exists Y \quad \text{\textit{is\_playful(X)}} \wedge \text{\textit{is\_fluffy(X)}} \wedge \text{\textit{friends(X,Y)}} \Rightarrow \text{\textit{ideal\_pet(X)}}. $$
 Assuming the domain being $\{$\textit{cat,hamster,alpaca}$\}$, the grounding of the predicate \textit{is\_playful(X)} are: \textit{is\_playful(cat)}, \textit{is\_playful(hamster)} and \textit{is\_playful(alpaca)}.
 
 
 
 
 Predicate logic allows us to represent knowledge about the world in a very compact manner: grounded atoms specify facts about the world, while logical formulas general properties and relationships that would otherwise be too cumbersome to write as facts.
 
 
 
 


 



\subsection{Logic programming}


\textit{Logic programming} uses language of predicate logic for computer programming.
It uses a subset of predicate logic in which the domains are restricted to \textit{Herbrand base} -- the set of all ground atoms that can be constructed from the constant and function symbols in the alphabet.
Furthermore, it restricts the formulas to be in the form of \textit{Horn clauses}.


A \textit{clause} is a disjunction of literals:

\begin{center}
	\texttt{A}$_1$  $\vee$ \ldots $\vee$ \texttt{A}$_n$.
\end{center}

More generally, if some of the literals in a clause are \textit{negated}

$$ \text{\texttt{A}}_1 \vee \text{\ldots} \vee \text{\texttt{A}}_n \vee \neg \text{\texttt{B}}_1 \vee \text{\texttt{\ldots}} \vee \neg \text{\texttt{B}}_m$$

then the clause can be written as an \textit{if-then} rule, for instance in the logic programming language \textit{Prolog}:

$$ \underbrace{\text{\texttt{A}}_1, \text{\ldots}, \text{\texttt{A}}_n}_{\text{\textit{head}}} \text{\texttt{:-}} \underbrace{\text{\texttt{B}}_1, \text{\texttt{\ldots}}, \text{\texttt{B}}_m}_{\text{\textit{body}}}.$$

Comma in the \textit{head} of the rule stands for a disjunction, while in the \textit{body} it indicates the conjunction of literals.
A \textit{Horn clause} is a clause with only one positive literal, i.e., $n = 1$.



A very attractive property of clausal logic is that it forms a very general framework for representing knowledge.
For example, a clausal statement with $n > 0$ and $m = 0$ indicates a fact.
If $n, m > 0$, then such a statement is a rule.
A statement wit $n=0$ and $m > 0$ represents a \textit{Prolog query}.
Moreover, even the learning algorithm itself can be represented as a set of clauses.



The main difference between predicate logic and logic programming is in the interpretation of the implication operator.
Predicate logic ($\Rightarrow$) interprets it in a declarative way, while logic programming takes a procedural interpretation of implication (\textit{:-}). 



\paragraph{Example}
Some pet owners are more picky than others and require a certain pedigree from their current and future pets.
Let us assume that royal ancestry exists among the animal species as well, and that some pet owners want royal pets.
How do we express this requirement in logic?
Let us define royal ancestry as follows: \textit{some is of royal ancestry if at least on of her ancestors was a king or queen}.
Starting simple, some is royal if he or she is a king or queen:
$$ \text{\textit{royal(X)}} \text{ :- } \text{\textit{is\_king(X)}}.$$
$$ \text{\textit{royal(X)}} \text{ :- } \text{\textit{is\_queen(X)}}.$$

Next, we can extend the rules to the children of kings and queens:
$$ \text{\textit{royal(X)}} \text{ :- } \text{\textit{parent(X,Y),is\_king(X,Y)}}.$$
$$ \text{\textit{royal(X)}} \text{ :- } \text{\textit{parent(X,Y),is\_queen(X,Y)}}.$$

Specifying these rules so that we could identify royal ancestry in general case is obviously tedious.
However, \textit{recursion} allows us to compactly compute all ancestors through the procedural interpretation of implication:

$$ \text{\textit{ancestor(X,Y)}} \text{ :- } \textit{parent(X,Y)}.$$
$$ \text{\textit{ancestor(X,Y)}} \text{ :- } \textit{parent(X,Z),ancestor(Z,Y)}.$$

The first clause state that $X$ is an ancestor of $Y$ if $X$ is a parent of $Y$.
The second clause states that $X$ is an ancestor of $Y$ is $X$ is a parent of $Y$ who is an ancestor of $Y$.
We can now define the rule for royal ancestry in a simple way:

$$ \text{\textit{royal(X)}} \text{ :- } \text{\textit{ancestor(Y,X),is\_king(Y)}}.$$
$$ \text{\textit{royal(X)}} \text{ :- } \text{\textit{ancestor(Y,X),is\_queen(Y)}}.$$












\subsection{Hierarchy of representation languages}



Propositional logic and logic programs are two extremes on the spectrum of possible data representations~\cite{LucRLbook}.
This spectrum of representations explores a tradeoff between the \textit{expressiveness} -- the complexity of what can be represented, and \textit{efficiency} -- how fast can we perform fundamental inference and learning tasks in certain representation. 
There is an intricate relationship between these properties: expressiveness comes with lower efficiency.
Therefore, resorting to a too powerful data representation as a default choice comes at a high computational cost; in contrast, choosing a less but sufficiently expressive representation offers better efficiency  without loss of information.


At the bottom of the ladder of expressivity are \textit{Boolean representations} (BR) based on propositional logic.
In Boolean representation, each example is associated with a fixed number of feature taking values from $\{true, false\}$.
This is similar to our pets data (Table \ref{tab:pets})  if all the values are replaced by $true$ and $false$.


One step up the ladder of expressiveness are \textit{multi-valued representations} (MVR).
These are similar to the Boolean representations, but each feature can have multiple ($> 2$) values.
This is the exact case as presented in Table \ref{tab:pets}.


\begin{table}
	\centering
	\caption{An example of the multi-instance representation\label{tab:mi}}
		\begin{tabular}{@{}lrrrrc@{}}
		\toprule
		\textbf{Owner} 	& \multicolumn{4}{c}{\textbf{Features}} 		& \textbf{Target} \\
			\cmidrule{2-5}
						& fluffy		& playful	& spits?		& bites?& 	\\
			\midrule
		
		Hannah			& 4			& yes		& yes		& no		& \checkmark \\
						& 3			& no			& yes		& no		&  \\
						& 5			& sometimes & yes		& yes	& \\
		\midrule
		Steve			& 1			& yes		& yes		& no		& $\mathbf{\times}$  \\
						& 4			& yes		& no			& no		& 	\\
		\midrule
		\multicolumn{6}{c}{$\ldots$} \\
		\bottomrule
		
		\end{tabular}	
\end{table}



One step further are \textit{multi-instance representations} (MIR)~\cite{Dietterich:1997:SMI:249678.249682}.
This representation class associates labels with \textit{sets of examples}.
Going back to out pet example, let us redefine the \gls{ml} model to do a different kind of predictions: \textit{do I like the taste in pets of a certain person?}
As one person can have multiple pets, multi-instance representation is well suited for this task.
An example is given in Table \ref{tab:mi}: an entity \textit{Hannah} owns three pets with different features, and the target information tell us that we like \textit{Hannah}'s taste in pets.
The target information is provided on the set of pets, not individual pets.
This is obviously a more difficult learning task the decision function being learned is also required to identify whether a \textit{relevant} information comes from all elements of the set or just a subset.







At the top of the ladder of expressiveness reside \textit{relational representation} (RR) and \textit{logic programs} (LP), with logic programs sitting on the very top.
A slight difference between the relational representation and logic programs, which makes their expressiveness differ, is that relational representations require that no functors are used and that the domains are finite.



It is interesting to study this representation classes from the perspective of \textit{reductions}:

\begin{quote}
	We say that the representation $X$ is \textit{reducible} to a representation $Y$, denoted as $X \sqsubseteq Y$, there exist two functions $f_e: \mathcal{L}_{eX} \rightarrow \mathcal{L}_{eY}$ mapping the examples $e$ from the representation $X$ to representation $Y$, and $f_h: \mathcal{L}_{hX} \rightarrow \mathcal{L}_{hY}$ mapping the decision function $h$ from the representation $X$ to representation $Y$.
\end{quote}


An important consequence of this reduction is the following.

\begin{quote}
	If a problem $E$ is representable by $X$, and $X$ is reducible to $Y$, then $f_e(E)$ is representable by $Y$, where $f_e(E) = \{ f_e(e) | e \in E\}$. The the learning problem $E$ in $X$ is solvable using a learning algorithm in $Y$.
\end{quote}



A very interesting theoretical result relating these representations is the following~\cite{10.1007/BFb0027304}:

\begin{quote}
	BR $\sqsubseteq$ MVR $\sqsubseteq$ MIR $\sqsubseteq$ RR $\sqsubseteq$ LP.
\end{quote}


Moreover, these reductions are \textit{proper}, meaning that of $X$ reduced to $Y$ then also $Y$ reduces to $X$.
If relational problems can be solved by boolean representations,  why bother with more expressive representation at all?


The reason lies in the expense that comes with reducing a more expressive representation to a less expressive one.
Take, for instance, reduction of MVR to BR.
To reduce a problem in MVR, say the data in Table \ref{tab:pets}, to the BR, we have to introduce a new variable for each \textit{attribute-value} pair, e.g., \textit{'fluffiness = 4'} becomes a feature.
Though the information in the data will be preserved by this reduction, the size of the data representation will increase exponentially.
One can also show that every reduction from the higher to lower step of the ladder yields an exponential increase in the data representation size~\cite{LucRLbook}.
This clearly demonstrates the strength of relational representation -- they can represent complex data \textit{compactly}, and it is worth keeping the relational representation if the task requires it.
Otherwise, reduction to the Boolean or Multi-valued representation could yield such a huge data representations making learning very difficult.




\section{Inductive logic programming}


So far, we have seen why predicate and clausal logic are a desirable framework for data representation.
What has not been discussed so far is their connection with machine learning.


\textit{Inductive logic programming} \cite{LucRLbook,Lavrac:1993:ILP:562956} is the field of \gls{ai} combining machine learning with logic programming representation language.
Intuitively, \gls{ilp} considers the problem of learning a logic theory, a set of clauses, predicting the target predicate.

More specifically, \gls{ilp} is defined as follows.

\begin{definition}{(\gls{ilp} learning task)}
	
	
\textbf{Given}
 a set of positive $\mathcal{E}^+$ and negative $\mathcal{E}^-$ examples, $\mathcal{E} = \mathcal{E}^+ \cup \mathcal{E}^-$,
 a language bias $\mathcal{L}$ -- a language of clauses,
 a covers relation $c$,
 a background knowledge or theory $\mathcal{B}$,


\textbf{Find} a set of clauses $\mathcal{T} \subset \mathcal{L}$ such that $\mathcal{T}$ (together with $\mathcal{B}$) covers all positive and no negative examples

\end{definition}



Several components form an \gls{ilp} problem.
First, there are positive and negative examples; going back to our \textit{pet} example, positive examples would be pets we previously liked, while the negative examples would be pets we would not like to purchase again.
Second, a typical \gls{ilp} learner requires a specification how to construct candidate clauses.
This is known as \textit{language bias}, and it is usually specified in a form of syntactic constraints on candidate formulas.
For instance, one can use only clauses with at most 3 literals in a body and at most 3 distinct logical variables.
Third, one has to provide a \textit{covers} relation.
Intuitively, \textit{covers} relation specifies how do we use a theory to make predictions about the examples.
Typical choice in \gls{ilp} is to use \textit{entailment} as \textit{covers} relation:

\begin{definition}{(Entailment)}
	Let $\mathcal{C}$ be a set of clauses and $c$ be a clause (a fact in our case). $\mathcal{C}$ \textit{logically entails} $c$, $\mathcal{C} \models c$, if and only if all models of $\mathcal{C}$ are also models of $c$. 
\end{definition}
Fourth, \textit{background knowledge} or \textit{theory} represent either any additional knowledge one might have about the examples.
In our pet example, the background knowledge consists of the information about diet, playfulness and biting habits of potential pets.
Additionally, background knowledge can contain additional \textit{rules} encoding experts knowledge, for instance: \textit{an animal that bites is potentially aggressive}.




\subsection{Learning as Search}

Learning \gls{ilp} models reduces to \textit{searching trough a set of candidate clauses and identifying a few most effective ones}.
As the space of all possible formulas would be enormous, searching it blindly would not be feasible.
Therefore, we are forced to search the space of possibilities conservatively so that we identify good candidates as fast as possible.
Many different \gls{ilp} algorithms have been proposed so far, but the vast majority of them follow one of the two prominent frameworks of exploring the space of candidate clauses: \textit{general-to-specific} and \textit{specific-to-general}.



To understand these two learning frameworks, we need to understand two notions -- \textit{generality} and \textit{specialization}.

\begin{definition}{(Generality)}
Let $c_1$ and $c_2$ $\in$ $\mathcal{L}$. 
Clause $c_1$ is \textit{more general} than clause $c_2$, $c_1 \preceq c_2$, if and only if all examples covered by $c_2$ and also covered by $c_1$. 
\end{definition}



\begin{definition}{(Specialization)}
Let $c_1$ and $c_2$ $\in$ $\mathcal{L}$. 
Clause $c_2$ is \textit{specialization} of clause $c_1$, $c_1 \preceq c_2$, if and only if all examples covered by $c_2$ and also covered by $c_1$. 
\end{definition}




\begin{algorithm}
	
	\caption{\gls{ilp} learning loop}
	\begin{algorithmic}
		\STATE $\text{Queue} \leftarrow \text{\textit{initialize}}$
		\STATE $\text{Examples} \leftarrow \{\text{\ldots}\}$
		\STATE $\text{Theory} \leftarrow \emptyset$
		
		\WHILE{not \textit{stop}}
			\STATE \textit{candidate} $\leftarrow$ take from Queue
			\IF{\textit{candidate} satisfies quality criteria}
				\STATE Theory $\leftarrow$ Theory $\cup$ \textit{candidate}
				\STATE $\text{Examples} \leftarrow \text{Examples} \setminus \{c(\text{\textit{candidate},Examples})\}$
			\ELSE
				\STATE $\text{Queue} \leftarrow \text{Queue} \cup \rho(\text{\textit{candidate}})$
			\ENDIF
			
			\STATE $\text{Queue} \leftarrow \text{prune(Queue)}$
				
		\ENDWHILE
		\RETURN Theory
		
	\end{algorithmic}
	\label{alg:ilploop}
\end{algorithm}


Both framework follow the same steps, illustrated in Algorithm \ref{alg:ilploop}, and differ only in small details.
The maintain a \textit{queue} of candidates, and iteratively test candidates from the \textit{queue}.
If a candidate clause satisfies a certain quality criteria, it is added to the final theory and all examples it \textit{entails} are removed from the example pool.
If a candidate does not satisfy the quality criteria, the refinements of the candidate (obtained through the $\rho$ function) are added to the candidate queue.
Afterwards, the queue of candidates is pruned by removing unnecessary candidates.
This procedure repeats until a certain stop criteria is met.



The two frameworks differ in two main steps: initialisation of the candidate queue, and the $\rho$ function.
The \textit{general-to-specific} approaches initialise the queue with an \textit{empty} clause and generate new candidate by adding new literals to a candidate clause, iteratively generating longer and longer clauses.
The \textit{specific-to-general} approaches state from very specific clauses, and gradually generalise them to cover more examples.




A wide landscape of \gls{ilp} algorithms comes from modifying these few choices choices: queue initialisation, $\rho$ function, stopping and quality criteria.
A common choice for the stopping criteria is to stop when no more examples can be covered.
The choice for a quality is a more difficult one, and it typically involves specifying the minimal accuracy for a clause to be acceptable, minimal number of examples to cover and so on.




\paragraph{\textbf{Example}}
Going back to the example in Table \ref{tab:pets}, assume we are given the following vocabulary: \{ \textit{legs/2}, \textit{fluffiness/2}, \textit{diary/2}, \textit{playful/2}, \textit{bites/1}, \textit{spits/1} \}.
We will assume that the predicates with two arguments, such as \textit{legs} and \textit{playful}, take an entity of a pet as the first argument and the second argument states the value of the attribute.
The predicate taking only one argument, for instance \textit{bites}, simply state that a pet bites.
Searching for a predictive \gls{ilp} model in a top-down manner will start with exploring all clauses with a single predicate in the body:

\begin{center}
	\textit{perfect\_pet(X) :- legs(X,2).} \quad \textit{perfect\_pet(X) :- legs(X,4).} 
	
	$\ldots$ 
	
	\textit{perfect\_pet(X) :- spits(X).} \quad \textit{perfect\_pet(X) :- bites(X).}
\end{center}


Clauses that were found useful, let us say that is \textit{perfect\_pet(X) :- legs(X,4).}, will be extended further:


\begin{center}
	\textit{perfect\_pet(X) :- legs(X,4),spits(X).} \quad \textit{perfect\_pet(X) :- legs(X,4),bites(X).} 
	
	$\ldots$ 
\end{center}

until a satisfactory model is found.




\section{Probabilistic logic programming}



\newglossaryentry{pilp}{name={PILP},description={Probabilistic inductive logic programming}}


Though clausal logic is a powerful representation framework, it still has a drawback when it comes to reasoning: it can only represent things being \textit{true} or \textit{false}, but cannot reason about uncertainty of conclusion.
Therefore, significant work has been devoted towards combining logic reasoning with probability theory, under the name of Statistical relational learning (\gls{srl}) and Probabilistic inductive logic programming.




Halpern introduces two formalisms to give the semantics to systems combining logic an probability \cite{Halpern90ananalysis}.
The first formalism assigns probabilities on the domain, i.e., the facts, and is suitable for probabilistic logic involving the uncertain facts.
The second formalism assigns probabilities on the possible worlds, and is suitable for giving semantics to formulas describing degrees of belief.
In the remainder of the chapter, we describe two prominent approaches within \gls{srl} and \gls{pilp}: \textit{Problog} and \textit{Markov logic networks}.


\subsection{Problog}

Problog is an probabilistic extension of Prolog where some facts can be annotated with the probabilities.
It is therefore a representation of the first formalism of the Halpern's systematisation.

An example of a Problog program is given in Figure~\ref{fig:problog}.
The central concept in Problog is a \textit{probabilistic fact}: ground fact $f$ annotated with a probability $p$ (\textit{p::f.}).
Each probabilistic fact corresponds to a Boolean random variable which is \textit{true} with probability $p$ and \textit{false} with probability $1-p$.
Next to the probabilistic facts, Problog consists of deterministic rules equivalent to Prolog clauses.
Such probabilistic facts together with rules define the following distribution $P_{F}$ over the truth assignments to the variables corresponding to probabilistic facts:

\begin{equation}
	P_F(F^{\prime}) = \prod_{f_i \in F^{\prime}}p_i \cdot \prod_{f_i\in F\setminus F^{\prime}}(1 - p_i).
\end{equation}


\begin{figure}
	$$\begin{aligned} 
		0.1{:: }{\mathtt {burglary}}. ~~~~&0.7{:: }{\mathtt {hears\_alarm(mary)}}. \nonumber \\ 
		\underbrace{0.2{:: }{\mathtt {earthquake}}.}_{probabilistic fact} ~~~~&0.4{:: }{\mathtt {hears\_alarm(john)}}.\nonumber \\ 
		\mathtt {alarm}&\text{ :- }{\mathtt {earthquake}}.\nonumber \\ 
		\mathtt {alarm}& \text{ :- } {\mathtt {burglary}}.\nonumber \\ 
		{{\mathtt {calls(X)}}}& \text{ :- } {\mathtt {alarm, hears\_alarm(X)}}.\nonumber \\ 
		{\mathtt{call}}& \text{ :- } {{\mathtt {calls(X)}}}. 	
	\end{aligned}$$
	\caption{Problog program of the alarm problem\label{fig:problog}}
\end{figure}


The distribution $P_F$ can be then used to defined the \textit{success probability} of a query $q$ -- the probability that $q$ (a ground atom) is \textit{true} is a randomly chosen program, as the sum over all programs that entail $q$:

$$
\begin{aligned} 
	P(q)&{:}{=}\sum \limits _{\begin{array}{c} F'\subseteq F \\ \exists \theta F'\cup R\models q\theta \end{array}} P_F(F')
\end{aligned}
$$

$$
\begin{aligned}
&= \sum \limits _{\begin{array}{c} F'\subseteq F \\ \exists \theta F'\cup R\models q\theta \end{array}} \prod _{f_i\in F'}p_i\cdot \prod _{f_i\in F\setminus F'}(1-p_i)\;. 
\end{aligned}
$$


\gls{srl} systems, such as Problog, are very flexible and can perform various inference tasks, not just the prediction task:
\begin{itemize}
	\item \textit{success probability:} a query $q$ is given, and the task is to compute $p(q)$
	\item \textit{marginal probability:} a set of queries $Q$ and evidence $E$ is given, and the task is to compute the marginal probability distribution of each $q \in Q$
	\item \textit{maximum aposteriori:} given a set of qeries $Q$ and evidence $E$, the task is to find the most likely truth-assignment $v$ to the atoms in $Q$
	\item \textit{most probable explanation:} the task is to find the most likely world where the given evidence query $e$ holds.
\end{itemize}



\subsection{Markov logic networks}












%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file, 
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
