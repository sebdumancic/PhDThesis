\chapter{Learning with logic}\label{ch:learninglogic}



This chapter briefly introduces the concepts of statistical relational learning.
It starts with a short introduction to logic, starting from the propositional logic and gradually climbs the ladder of complexity all the way to the logic programming.
It continues with a brief introduction to Inductive logic programming.
Finally, it touches upon the contemporary topic of \textit{Probabilistic} Inductive Logic Programming which combines Inductive Logic Programming  with probability theory to quantify the uncertainty of the reasoning.




\section{Representing data with logic}





\subsection{Propositional logic}

Propositional logic is a formalism for reasoning about the truth assignments of \textit{propositions}.
Propositions are statements about the world being modelled, and can be \textit{true} or \textit{false}.


The propositions are constructed from propositional \textit{variables} and \textit{connectivity operators}.
Propositional variables denote \textit{aspects} of the world considered by the model, for instance, \textit{sun}, \textit{rainbow} and \textit{bob\_runs}.
Variables are used in propositions as \textit{literals} -- a propositional variable or its negation.
The connectivity operators compose literals into more complicated statements.
Such operators are \textit{conjunction} (AND operator), \textit{disjunction} (OR operator), \textit{implication} (IF-THEN operator) and \textit{equivalence} (IF-AND-ONLY-IF	operator).


A \textit{logical theory} is a collection of propositions, more precisely, a conjunction of propositions.
An \textit{interpretation} is a truth assignment for each of the propositional variables.
An interpretation satisfies a given proposition if it evaluates to \textit{true} for the given truth assignments to the variables.
An interpretation that satisfies the proposition is a \textit{model} of that proposition.



\paragraph{Example} The proposition
$$\text{\texttt{playful}} \wedge \text{\texttt{fluffy}} \Rightarrow \text{\texttt{ideal\_pet}} $$
encodes that when something is playful (variable \texttt{playful} is true) and fluffy (variable \texttt{fluffy} is true) then it is an ideal pet (variable \texttt{ideal\_pet} is true).
Every interpretation in which \texttt{ideal\_pet} is true is a model of this proposition.




Once the theory describing the knowledge is available, different \textit{inference} tasks can be considered.
One of the fundamental tasks is that of \textit{consistency} or \textit{satisfiability} checking, which checks whether the theory has a model.
The task of \textit{validity} checking checks whether every interpretation is a model.
The task of \textit{model counting}, a generalisation of both aforementioned tasks, counts the number of models of the theory.









\subsection{Predicate logic}


Propositional logic is a suitable framework for drawing inferences about individual objects or examples (where each example is an interpretation), but encoding more complex knowledge in form of relations among objects is extremely tedious.
For instance, to indicate that two animals are of the same species would require introducing new Boolean variables for each pair of animals, such as \texttt{same\_species\_dog\_cat}, and specifying their truth assignments.



To overcome this issue, \textit{predicate logic} extends  propositional logic with \textit{objects} and \textit{relations} among them, resulting in a powerful language for representing mathematical formalisms.
An especially attractive feature of predicate logic is its universal \textit{inference algorithm} -- one can state a set of axioms, or facts, and theorems in predicate logic and rely on the \textit{resolution} \cite{Robinson:1965:Resolution} inference algorithm to derive new axioms and theorems from the old ones.



The language of predicate logic is similar to the one of the propositional logic.
The core building blocks of predicate logic formulas are \textit{four} types of symbols: \textit{constant} (referring to individual objects), \textit{variable} (referring to groups of objects), \textit{function} and \textit{predicate} symbols.


The statements in predicate logic, the formulas, are composed of \textit{terms}, \textit{atoms} and \textit{connectivity operators}.
A \textit{term} is defined as:
\begin{itemize}
	\item a constant is a term
	\item a variable is a term
	\item if $f / n$ is a function symbol and $t_1,t_2,...,t_n$ are terms, then function $f(t_1,...,t_n)$ is a term.
\end{itemize}


An \textit{atom} is of the form $p(t_1,...,t_n)$ where $p/n$ is a predicate symbol and $t_1,...,t_n$ are terms.
A \textit{literal} is an atom or its negation.


Finally, a \textit{formula} in predicate logic is defined as:
\begin{itemize}
	\item An atom is a formula
	\item \texttt{true} and \texttt{false} are formulas
	\item If $\phi$ and $\psi$ are formulas, so are $\phi \wedge \psi$, $\phi \vee \psi$, $\phi \Rightarrow \psi$, $\phi \Leftrightarrow \psi$ and $\not \phi$
	\item If $\phi$ is a formula and $X$ is a variable, so are $\forall X \phi$ and $\exists X \phi$.
\end{itemize}


A Formula is \textit{ground} if it does not contain logical variables, meaning that the variables are \textit{bound} to the exact objects or individuals.







Evaluating formulas in predicate logic is not as simple as in the propositional logic.
The main complication comes from the usage of variables.
Thus, in order to specify the interpretation one first has to, for each predicate,  map logical variables to a set of domain elements, i.e., each predicate has to be \textit{grounded}.
Once groundings are obtained, each grounding of a predicate is associated with \texttt{true} or \texttt{false}.



\paragraph{Example} Mapping the previous example in propositional logic to predicate logic results in the following formula:

$$\forall X \quad \text{\texttt{is\_playful(X)}} \wedge \text{\texttt{is\_fluffy(X)}} \Rightarrow \text{\texttt{ideal\_pet(X)}}. $$

 Predicate logic allows us to easily express more complex knowledge relating different objects.
 For instance, we can refine the previous formula and add a condition that an ideal pet also needs to have at least one friend:
 $$\forall X, \exists Y \quad \text{\texttt{is\_playful(X)}} \wedge \text{\texttt{is\_fluffy(X)}} \wedge \text{\texttt{friends(X,Y)}} \Rightarrow \text{\texttt{ideal\_pet(X)}}. $$
 Assuming the domain $\{$\texttt{cat,hamster,alpaca}$\}$, the groundings of the predicate \texttt{is\_playful(X)} are: \texttt{is\_playful(cat)}, \texttt{is\_playful(hamster)} and \texttt{is\_playful(alpaca)}.




 Predicate logic allows us to represent knowledge about the world in a very compact manner: grounded atoms specify facts about the world, while logical formulas general properties and relationships that would otherwise be too cumbersome to write as facts.










\subsection{Logic programming}


\textit{Logic programming} uses the language of predicate logic for computer programming.
It uses a subset of predicate logic in which the domains are restricted to the \textit{Herbrand base} -- the set of all ground atoms that can be constructed from the constant and function symbols in the alphabet.
Furthermore, it restricts the formulas to be in the form of \textit{Horn clauses}.


A \textit{clause} is a disjunction of literals:

\begin{center}
	\texttt{A}$_1$  $\vee$ \ldots $\vee$ \texttt{A}$_n$.
\end{center}

More generally, if some of the literals in a clause are \textit{negated}

$$ \text{\texttt{A}}_1 \vee \text{\ldots} \vee \text{\texttt{A}}_n \vee \neg \text{\texttt{B}}_1 \vee \text{\texttt{\ldots}} \vee \neg \text{\texttt{B}}_m$$

then the clause can be written as an \textit{if-then} rule, for instance in the logic programming language \textit{Prolog}:

$$ \underbrace{\text{\texttt{A}}_1, \text{\ldots}, \text{\texttt{A}}_n}_{\text{\textit{head}}} \text{\texttt{:-}} \underbrace{\text{\texttt{B}}_1, \text{\texttt{\ldots}}, \text{\texttt{B}}_m}_{\text{\textit{body}}}.$$

A comma in the \textit{head} of the rule stands for a disjunction, while in the \textit{body} it indicates the conjunction of literals.
A \textit{Horn clause} is a clause with only one positive literal, i.e., $n = 1$.



A very attractive property of clausal logic is that it forms a very general framework for representing knowledge.
For example, a clausal statement with $n > 0$ and $m = 0$ indicates a fact.
If $n, m > 0$, then such a statement is a rule.
A statement with $n=0$ and $m > 0$ represents a \textit{Prolog query} -- a statement whose truth assignment we want to check.
Moreover, even the learning algorithm itself can be represented as a set of clauses.



The main difference between predicate logic and logic programming is in the interpretation of the implication operator.
Predicate logic ($\Rightarrow$) interprets it in a declarative way, while logic programming takes a procedural interpretation of implication (\textit{:-}) -- meaning that the head of the clause is \textit{true} every time the body is \textit{true}.



\paragraph{Example}
Some pet owners are pickier than others and require a certain pedigree from their current and future pets.
Let us assume that royal ancestry exists among the animal species as well and that some pet owners want royal pets.
How do we express this requirement in logic?
Let us define royal ancestry as follows: \textit{someone is of royal ancestry if at least one of her ancestors was a king or queen}.
Starting simple, some is royal if he or she is a king or queen:
$$ \text{\texttt{royal(X)}} \text{ :- } \text{\texttt{is\_king(X)}}.$$
$$ \text{\texttt{royal(X)}} \text{ :- } \text{\texttt{is\_queen(X)}}.$$

Next, we can extend the rules to the children of kings and queens:
$$ \text{\texttt{royal(X)}} \text{ :- } \text{\texttt{parent(X,Y),is\_king(X,Y)}}.$$
$$ \text{\texttt{royal(X)}} \text{ :- } \text{\texttt{parent(X,Y),is\_queen(X,Y)}}.$$

Specifying these rules so that we could identify royal ancestry in general case is obviously tedious.
However, \texttt{recursion} allows us to compactly compute all ancestors through the procedural interpretation of implication:

$$ \text{\texttt{ancestor(X,Y)}} \text{ :- } \texttt{parent(X,Y)}.$$
$$ \text{\texttt{ancestor(X,Y)}} \text{ :- } \texttt{parent(X,Z),ancestor(Z,Y)}.$$

The first clause state that $X$ is an ancestor of $Y$ if $X$ is a parent of $Y$.
The second clause states that $X$ is an ancestor of $Y$ is $X$ is a parent of $Y$ who is an ancestor of $Y$.
We can now define the rule for royal ancestry in a simple way:

$$ \text{\texttt{royal(X)}} \text{ :- } \text{\texttt{ancestor(Y,X),is\_king(Y)}}.$$
$$ \text{\texttt{royal(X)}} \text{ :- } \text{\texttt{ancestor(Y,X),is\_queen(Y)}}.$$












\subsection{Hierarchy of representation languages}



Propositional logic and logic programs are two extremes on the spectrum of possible data representations~\cite{LucRLbook}.
This spectrum of representations explores a trade-off between the \textit{expressiveness} -- the complexity of what can be represented, and \textit{efficiency} -- how fast can we perform fundamental inference and learning tasks in a certain representation class.
There is an intricate relationship between these properties: expressiveness comes with lower efficiency.
Therefore, resorting to a too powerful data representation as a default choice comes at a high computational cost; in contrast, choosing a less but sufficiently expressive representation offers better efficiency  without loss of information.


At the bottom of the ladder of expressivity are \textit{Boolean representations} (BR) based on propositional logic.
In Boolean representation, each example is associated with a fixed number of features taking values from $\{true, false\}$.
This is similar to our pets data (Table \ref{tab:pets})  if all the values are replaced by $true$ and $false$.


One step up the ladder of expressiveness are \textit{multi-valued representations} (MVR).
These are similar to the Boolean representations, but each feature can have multiple ($> 2$) values.
This is the exact case as presented in Table \ref{tab:pets}.


\begin{table}
	\centering
	\caption{An example of the multi-instance representation\label{tab:mi}}
		\begin{tabular}{@{}lrrrrc@{}}
		\toprule
		\textbf{Owner} 	& \multicolumn{4}{c}{\textbf{Features}} 		& \textbf{Target} \\
			\cmidrule{2-5}
						& fluffy		& playful	& spits?		& bites?& 	\\
			\midrule

		Hannah			& 4			& yes		& yes		& no		& \checkmark \\
						& 3			& no			& yes		& no		&  \\
						& 5			& sometimes & yes		& yes	& \\
		\midrule
		Steve			& 1			& yes		& yes		& no		& $\mathbf{\times}$  \\
						& 4			& yes		& no			& no		& 	\\
		\midrule
		\multicolumn{6}{c}{$\ldots$} \\
		\bottomrule

		\end{tabular}
\end{table}



One step further are \textit{multi-instance representations} (MIR)~\cite{Dietterich:1997:SMI:249678.249682}.
This representation class associates labels with \textit{sets of examples}.
Going back to out pet example, let us redefine the \gls{ml} model to do a different kind of predictions: \textit{do I like the taste in pets of a certain person?}
As one person can have multiple pets, multi-instance representation is well suited for this task.
An example is given in Table \ref{tab:mi}: an entity \textit{Hannah} owns three pets with different features, and the target information tells us that we like \textit{Hannah}'s taste in pets.
The target information is provided on the set of pets, not individual pets.
This is obviously a more difficult learning task the decision function being learned is also required to identify whether a \textit{relevant} information comes from all elements of the set or just a subset.







At the top of the ladder of expressiveness reside \textit{relational representation} (RR) and \textit{logic programs} (LP), with logic programs sitting on the very top.
A slight difference between the relational representation and logic programs, which makes their expressiveness differ, is that relational representations require that no functors are used and that the domains are finite.



It is interesting to study this representation classes from the perspective of \textit{reductions}:

\begin{quote}
	We say that the representation $X$ is \textit{reducible} to a representation $Y$, denoted as $X \sqsubseteq Y$, there exist two functions $f_e: \mathcal{L}_{eX} \rightarrow \mathcal{L}_{eY}$ mapping the examples $e$ from the representation $X$ to representation $Y$, and $f_h: \mathcal{L}_{hX} \rightarrow \mathcal{L}_{hY}$ mapping the decision function $h$ from the representation $X$ to representation $Y$.
\end{quote}


An important consequence of this reduction is the following.

\begin{quote}
	If a problem $E$ is representable by $X$, and $X$ is reducible to $Y$, then $f_e(E)$ is representable by $Y$, where $f_e(E) = \{ f_e(e) | e \in E\}$. The the learning problem $E$ in $X$ is solvable using a learning algorithm in $Y$.
\end{quote}



A very interesting theoretical result relating these representations is the following~\cite{10.1007/BFb0027304}:

\begin{quote}
	BR $\sqsubseteq$ MVR $\sqsubseteq$ MIR $\sqsubseteq$ RR $\sqsubseteq$ LP.
\end{quote}


Moreover, these reductions are \textit{proper}, meaning that of $X$ reduced to $Y$ then also $Y$ reduces to $X$.
If relational problems can be solved by Boolean representations,  why bother with more expressive representation at all?


The reason lies in the expense that comes with reducing a more expressive representation to a less expressive one.
Take, for instance, reduction of MVR to BR.
To reduce a problem in MVR, say the data in Table \ref{tab:pets}, to the BR, we have to introduce a new variable for each \textit{attribute-value} pair, e.g., \textit{'fluffiness = 4'} becomes a feature.
Though the information in the data will be preserved by this reduction, the size of the data representation will increase exponentially.
One can also show that every reduction from the higher to lower step of the ladder yields an exponential increase in the data representation size~\cite{LucRLbook}.
This clearly demonstrates the strength of relational representation -- they can represent complex data \textit{compactly}, and it is worth keeping the relational representation if the task requires it.
Otherwise, reduction to the Boolean or Multi-valued representation could yield such a huge data representations making learning very difficult.




\section{Inductive logic programming}


So far, we have seen why predicate and clausal logic are a desirable framework for data representation.
What has not been discussed so far is their connection with machine learning.


\textit{Inductive logic programming} \cite{LucRLbook,Lavrac:1993:ILP:562956} is the field of \gls{ai} combining machine learning with logic programming as the representation language.
Intuitively, \gls{ilp} considers the problem of learning a logic theory, a set of clauses, predicting the target predicate.

More specifically, \gls{ilp} is defined as follows:

\begin{quote}
	\textbf{Given}
	 a set of positive $\mathcal{E}^+$ and negative $\mathcal{E}^-$ examples, $\mathcal{E} = \mathcal{E}^+ \cup \mathcal{E}^-$,
	 a language bias $\mathcal{L}$ -- a language of clauses,
	 a covers relation $c$,
	 a background knowledge or theory $\mathcal{B}$,


	\textbf{Find} a set of clauses $\mathcal{T} \subset \mathcal{L}$ such that $\mathcal{T}$ (together with $\mathcal{B}$) covers all positive and no negative examples
\end{quote}

% \begin{definition}{(\gls{ilp} learning task)}
%
%
% \textbf{Given}
%  a set of positive $\mathcal{E}^+$ and negative $\mathcal{E}^-$ examples, $\mathcal{E} = \mathcal{E}^+ \cup \mathcal{E}^-$,
%  a language bias $\mathcal{L}$ -- a language of clauses,
%  a covers relation $c$,
%  a background knowledge or theory $\mathcal{B}$,
%
%
% \textbf{Find} a set of clauses $\mathcal{T} \subset \mathcal{L}$ such that $\mathcal{T}$ (together with $\mathcal{B}$) covers all positive and no negative examples
%
% \end{definition}



Several components form an \gls{ilp} problem.
First, there are positive and negative examples; going back to our \textit{pet} example, positive examples would be pets we previously liked, while the negative examples would be pets we would not like to purchase again.
Second, a typical \gls{ilp} learner requires a specification of how to construct candidate clauses.
This is known as \textit{language bias}, and it is usually specified in a form of syntactic constraints on candidate formulas.
For instance, one can use only clauses with at most 3 literals in a body and at most 3 distinct logical variables.
Third, one has to provide a \textit{covers} relation.
Intuitively, \textit{covers} relation specifies how do we use a theory to make predictions about the examples.
Typical choice in \gls{ilp} is to use \textit{entailment} as \textit{covers} relation:

% \begin{definition}{(Entailment)}
% 	Let $\mathcal{C}$ be a set of clauses and $c$ be a clause (a fact in our case). $\mathcal{C}$ \textit{logically entails} $c$, $\mathcal{C} \models c$, if and only if all models of $\mathcal{C}$ are also models of $c$.
% \end{definition}

\begin{quote}
	Let $\mathcal{C}$ be a set of clauses and $c$ be a clause (a fact in our case). $\mathcal{C}$ \textit{logically entails} $c$, $\mathcal{C} \models c$, if and only if all models of $\mathcal{C}$ are also models of $c$.
\end{quote}


Fourth, \textit{background knowledge} or \textit{theory} represent any additional knowledge one might have about the provided domain.
In our pet example, the background knowledge consists of the information about diet, playfulness and biting habits of potential pets.
Additionally, background knowledge can contain additional \textit{rules} encoding experts knowledge, for instance: \textit{an animal that bites is potentially aggressive}.




\subsection{Learning as Search}

Learning \gls{ilp} models reduces to \textit{searching trough a set of candidate clauses and identifying a few most effective ones}.
As the space of all possible formulas would be enormous, searching it blindly would not be feasible.
Therefore, we are forced to search the space of possibilities conservatively so that we identify good candidates as fast as possible.
Many different \gls{ilp} algorithms have been proposed so far, but the vast majority of them follow one of the two prominent frameworks of exploring the space of candidate clauses: \textit{general-to-specific} and \textit{specific-to-general}.



To understand these two learning frameworks, we need to understand two notions -- \textit{generality} and \textit{specialisation}.

\begin{definition}{(Generality)}
Let $c_1$ and $c_2$ $\in$ $\mathcal{L}$.
Clause $c_1$ is \textit{more general} than clause $c_2$, $c_1 \preceq c_2$, if and only if all examples covered by $c_2$ and also covered by $c_1$.
\end{definition}



\begin{definition}{(Specialisation)}
Let $c_1$ and $c_2$ $\in$ $\mathcal{L}$.
Clause $c_2$ is \textit{specialisation} of clause $c_1$, $c_1 \preceq c_2$, if and only if all examples covered by $c_2$ and also covered by $c_1$.
\end{definition}




\begin{algorithm}

	\caption{The \gls{ilp} learning loop}
	\begin{algorithmic}
		\STATE $\text{Queue} \leftarrow \text{\textit{initialise}}$
		\STATE $\text{Examples} \leftarrow \{\text{\ldots}\}$
		\STATE $\text{Theory} \leftarrow \emptyset$

		\WHILE{not \textit{stop}}
			\STATE \textit{candidate} $\leftarrow$ take from Queue
			\IF{\textit{candidate} satisfies quality criteria}
				\STATE Theory $\leftarrow$ Theory $\cup$ \textit{candidate}
				\STATE $\text{Examples} \leftarrow \text{Examples} \setminus \{c(\text{\textit{candidate},Examples})\}$
			\ELSE
				\STATE $\text{Queue} \leftarrow \text{Queue} \cup \rho(\text{\textit{candidate}})$
			\ENDIF

			\STATE $\text{Queue} \leftarrow \text{prune(Queue)}$

		\ENDWHILE
		\RETURN Theory

	\end{algorithmic}
	\label{alg:ilploop}
\end{algorithm}


Both frameworks follow the same steps, illustrated in Algorithm \ref{alg:ilploop}, and differ only in small details.
They maintain a \textit{queue} of candidates, and iteratively test candidates from the \textit{queue}.
If a candidate clause satisfies a certain quality criterion, it is added to the final theory and all examples it \textit{entails} are removed from the example pool.
If a candidate does not satisfy the quality criteria, the refinements of the candidate (obtained through the $\rho$ function) are added to the candidate queue.
Afterwards, the queue of candidates is pruned by removing unnecessary candidates.
This procedure repeats until a certain stop criterion is met.



The two frameworks differ in two main steps: initialisation of the candidate queue, and the $\rho$ function.
The \textit{general-to-specific} approaches initialise the queue with an \textit{empty} clause and generate new candidate by adding new literals to a candidate clause, iteratively generating longer and longer clauses.
The \textit{specific-to-general} approaches state from very specific clauses, and gradually generalise them to cover more examples.




A wide landscape of \gls{ilp} algorithms comes from modifying these few choices: queue initialisation, $\rho$ function, stopping and quality criteria.
A common choice for the stopping criteria is to stop when no more examples can be covered.
The choice for a quality is a more difficult one, and it typically involves specifying the minimal accuracy for a clause to be acceptable, the minimal number of examples to cover and so on.




\paragraph{\textbf{Example}}
Going back to the example in Table \ref{tab:pets}, assume we are given the following vocabulary: \{ \texttt{legs/2}, \texttt{fluffiness/2}, \texttt{diary/2}, \texttt{playful/2}, \texttt{bites/1}, \texttt{spits/1} \}.
We will assume that the predicates with two arguments, such as \texttt{legs} and \texttt{playful}, take an entity of a pet as the first argument and the second argument states the value of the attribute.
The predicate taking only one argument, for instance \texttt{bites}, simply state that a pet bites.
Searching for a predictive \gls{ilp} model in a top-down manner will start by exploring all clauses with a single predicate in the body:

\begin{center}
	\texttt{perfect\_pet(X) :- legs(X,2).} \quad \texttt{perfect\_pet(X) :- legs(X,4).}

	$\ldots$

	\texttt{perfect\_pet(X) :- spits(X).} \quad \texttt{perfect\_pet(X) :- bites(X).}
\end{center}


Clauses that were found useful, let us say that is \texttt{perfect\_pet(X) :- legs(X,4).}, will be extended further:


\begin{center}
	\texttt{perfect\_pet(X) :- legs(X,4),spits(X).} \quad \texttt{perfect\_pet(X) :- legs(X,4),bites(X).}

	$\ldots$
\end{center}

until a satisfactory model is found.







\subsection{Language bias}
\label{ch2:languagebias}

Blindly searching over the space of possible clauses usually generates huge search spaces.
To tackle this issue, many \gls{ilp} system rely on \textit{language bias}~\cite{DBLP:reference/ml/Blockeel17} to focus the search.


Language bias provides a specification of how the provided predicates can \textit{interact} with each other.
This typically includes specifying the following information


\paragraph{Argument types.} Given an predicate \texttt{b/2} (where \texttt{/2} defines the number of arguments the predicate takes), each argument has an associated \textit{type}. For instance, the predicate \textit{friends/2} operates only between entities of type \texttt{person}: both arguments are of the type \texttt{person}.


\paragraph{Argument roles.} Each argument of a predicate has an associated \textit{role}, which specifies how the predicate can be introduced in a clause.
Arguments can be of the following types:
\begin{itemize}
	\item \textbf{Input (+):} an input argument needs to be \textit{bounded} to already existing variable in a clause, or any of the variables from the head of the clause
	\item \textbf{Output (-):} an output argument introduces a new variable in the clause
	\item \textbf{Constant (\#):} a constant must be introduced in the place of the argument.
\end{itemize}

For instance, assume you want to extend the clause \texttt{h(X,Y) :- b$_1$(X).} with a predicate \texttt{b$_2$/2} having the roles specified as \texttt{b$_2$(+,\#)}.
Then the first argument of \texttt{b$_2$/2} has to be bounded to one of the existing variables \texttt{\{X,Y\}}, where the constant has to be introduced instead of the second argument (assume \texttt{c$_1$}).
The possible extensions are then:
\begin{center}
	\texttt{h(X,Y) :- b$_1$(X),b$_2$(X,c$_1$).}


	\texttt{h(X,Y) :- b$_1$(X),b$_2$(Y,c$_1$).}
\end{center}

It the predicate \texttt{b$_2$/2} would be specified as \texttt{b$_2$(+,-)}, the second argument has to introduce a new variable, e.g.,
\begin{center}
	\texttt{h(X,Y) :- b$_1$(X),b$_2$(X,Z).}
\end{center}


\paragraph{Syntactic restrictions.}
Constraints might be imposed on the syntax of the clauses, for instance
\begin{itemize}
	\item \textbf{Connectivity} specifies which connectivity operators can be used in the bodies of the clauses: conjunction, disjunction and negation. We currently use only the conjunctions and disjunctions.
	\item \textbf{Length bound} limits the lengths of the body of a clause.
	\item \textbf{Term bound} introduces the upper bound on the \textit{maximal} number of terms in a clause.
\end{itemize}

Given these constraints, we can reduce the search space substantially which can further be pruned through generalisation and specialisation.
% Given these constraints, we simply enumerate all formulas of bounded length that satisfy them; formulas enumerated in this way form the language bias.
% The same principle is used for generating the language bias of both encoder and decoder clauses.









\section{Probabilistic logic programming}



\newglossaryentry{pilp}{name={PILP},description={Probabilistic inductive logic programming}}
Though clausal logic is a powerful representation framework, it still has a drawback when it comes to reasoning: it can only represent things being \textit{true} or \textit{false}, but cannot reason about the uncertainty of conclusion.
Therefore, significant work has been devoted towards combining logic reasoning with probability theory, under the name of Statistical relational learning (\gls{srl}) and Probabilistic inductive logic programming.




Halpern introduces two formalisms for giving the semantics to systems combining logic an probability \cite{Halpern90ananalysis}.
The first formalism assigns probabilities on the domain, i.e., the facts, and is suitable for probabilistic logic involving the uncertain facts.
The second formalism assigns probabilities on the possible worlds, and is suitable for giving semantics to formulas describing degrees of belief.
In the remainder of the chapter, we describe two prominent approaches within \gls{srl} and \gls{pilp}: \textit{Problog} and \textit{Markov logic networks}.


\subsection{Problog}

\textit{Problog}~\cite{DeRaedt:2007:PPP:1625275.1625673} is a probabilistic extension of Prolog where some facts can be annotated with the probabilities.
It is, therefore, a representative of the first formalism of the Halpern's systematisation.

An example of a Problog program is given in Figure~\ref{fig:problog}.
The central concept in Problog is a \textit{probabilistic fact}: ground fact $f$ annotated with a probability $p$ (e. g., $0.8{:: }{\mathtt {playful(alpaca)}}$).
\textit{Deterministic facts} are simply the probabilistic facts with $p = 1.0$.
Each probabilistic fact corresponds to a Boolean random variable which is \textit{true} with probability $p$ and \textit{false} with probability $1-p$.
Next to the probabilistic facts, Problog consists of deterministic rules equivalent to Prolog clauses (e. g., ${\mathtt {cuddly(X)} \text{ :- }{\mathtt {fluffiness(X,Y),Y >= 4}}.}$).
Probabilistic rules (e. g., $0.3{:: }{\mathtt {bites(X)}} \text{ :- }{\mathtt {diet(X,carnivore)}}.$) are syntactic sugars which simply introduce a new probabilistic fact reflecting the probability of the rule every time the deterministic rule is \texttt{true}.
Such probabilistic facts together with rules define the following distribution $P_{F}$ over the truth assignments to the variables corresponding to probabilistic facts:

\begin{equation}
	P_F(F^{\prime}) = \prod_{f_i \in F^{\prime}}p_i \cdot \prod_{f_i\in F\setminus F^{\prime}}(1 - p_i).
\end{equation}


\begin{figure}
	$$\begin{aligned}
		{\mathtt {legs(alpaca,4)}}. ~~~~&0.9{:: }{\mathtt {friends(alpaca,otter)}}. \nonumber \\
		{\mathtt {fluffiness(alpaca,5)}}. ~~~~&0.8{:: }{\mathtt {playful(alpaca)}}. \nonumber \\
		\underbrace{{\mathtt {diet(alpaca,herbivore)}}.}_{deterministic ~ fact} ~~~~&\underbrace{0.6{:: }{\mathtt {spits(alpaca)}}.}_{probabilistic ~ fact} \nonumber \\
		\mathtt {cuddly(X)}\text{ :- }{\mathtt {fluffiness(X,Y),Y >= 4}}. ~~~~&  \nonumber \\
		\mathtt {ideal\_pet(X)} \text{ :- }{\mathtt {cuddly(X)}}. ~~~~& 0.3{:: }{\mathtt {bites(X)}} \text{ :- }{\mathtt {diet(X,carnivore)}}. \nonumber \\
		\underbrace{\mathtt {ideal\_pet(X)}\text{ :- }{\mathtt {friends(X,otter)}}.}_{deterministic ~ rules} ~~~~& \underbrace{0.2{:: }{\mathtt {cuddly(X)}} \text{ :- }{\mathtt {bites(X)}}.}_{probabilistic ~ rules} \nonumber \\
		%\mathtt {ideal\_pet(X)}&\text{ :- }{\mathtt {cuddly(X)}}.\nonumber \\
		%\mathtt {ideal\_pet(X)}&\text{ :- }{\mathtt {friends(X,otter)}}.
	\end{aligned}$$
	\caption[Example Problog program]{Problog program for the pet decision problem. Probabilistic facts  $0.8::$\texttt {playful(alpaca).} states that \texttt{alpaca} us playful with certainty of $80 \%$. Deterministic fact \texttt{legs(alpaca,4).} states the \texttt{alpaca} has four legs with certainty of $100 \%$.  A rule \texttt{cuddly(X)} :- \texttt{fluffiness(X,Y),Y >= 4.} states that a pet is \texttt{cuddly} is its \texttt{fluffiness} level is greater or equal to 4. \label{fig:problog}}
\end{figure}


The distribution $P_F$ can be then used to defined the \textit{success probability} of a query $q$ -- the probability that $q$ (a ground atom) is \textit{true} is a randomly chosen program, as the sum over all programs that entail $q$:

$$
\begin{aligned}
	P(q)&{:}{=}\sum \limits _{\begin{array}{c} F'\subseteq F \\ \exists \theta F'\cup R\models q\theta \end{array}} P_F(F')
\end{aligned}
$$

$$
\begin{aligned}
&= \sum \limits _{\begin{array}{c} F'\subseteq F \\ \exists \theta F'\cup R\models q\theta \end{array}} \prod _{f_i\in F'}p_i\cdot \prod _{f_i\in F\setminus F'}(1-p_i)\;.
\end{aligned}
$$


\gls{srl} systems, such as Problog, are very flexible and can perform various inference tasks, not just the prediction task:
\begin{itemize}
	\item \textit{success probability:} a query $q$ is given, and the task is to compute $p(q)$
	\item \textit{marginal probability:} a set of queries $Q$ and evidence $E$ is given, and the task is to compute the marginal probability distribution of each $q \in Q$
	\item \textit{maximum aposteriori:} given a set of queries $Q$ and evidence $E$, the task is to find the most likely truth-assignment $v$ to the atoms in $Q$
	\item \textit{most probable explanation:} the task is to find the most likely world where the given evidence query $e$ holds.
\end{itemize}





\subsection{Markov logic networks}

\newglossaryentry{mln}{name={MLN},description={Markov Logic Network}}
\textit{Markov logic networks} (\gls{mln})~\cite{Richardson2006} fall in the second category of Halpern's classification as they associate probabilities with possible worlds.
\gls{mln}s start from the view that the formulas in first-order logic can be seen as a set of hard constraints on the set of possible worlds: if a world violates one logical formula, its probability is zero.
\gls{mln}s aim to soften these constraints by making the worlds that violate the formulas less probable, but not impossible.
Each formula thus has an associated weight that specifies how strong the constraint is.


Formally, a Markov logic network is a set of pairs $(F_i,w_i)$, where $F_i$ is a formula written in first-order logic and $w_i$ is a real number reflecting the strength of the constraint.
An \gls{mln} can be seen as a template for constructing a a Markov network~\cite{koller2009probabilistic}, given the set of constants $C$.
\gls{mln}s defined the probability distribution over possible worlds as

$$ P(X=x) = \frac{1}{Z} \exp \left(  \sum_{i}w_in_i(x) \right) $$

where $n_(x)$ is the number of true groundings of the formula $F_i$ in $x$ and $x$ represent the truth assignments to atoms appearing in $F_i$.
Similar to Problog, \gls{mln}s are capable of answering different types of queries.


Figure \ref{fig:mln} shows the \gls{mln} translation of the pet decision problem introduced before.
In contrast to the Problog model, \gls{mln}s cannot represent uncertain facts and therefore all facts are deterministic.
Uncertainty in \gls{mln}s can be handled only through the formulas which can be stochastic (e. g., $w_1 ~~ {\mathtt {diet(X,carnivore)}} \Rightarrow {\mathtt {bites(X)}} $) with $w_1$ reflecting the strength of the constraint, and deterministic (e. g., ${\mathtt {cuddly(X)}} \Rightarrow \mathtt {ideal\_pet(X)}.$) with the associated weight being \texttt{infinity} (meaning that no possible world can break it).






\begin{figure}
	$$\begin{aligned}
		{\mathtt {legs(alpaca,4)}} ~~~~&{\mathtt {friends(alpaca,otter)}} \nonumber \\
		{\mathtt {fluffiness(alpaca,5)}} ~~~~&{\mathtt {playful(alpaca)}} \nonumber \\
		{\mathtt {diet(alpaca,herbivore)}} ~~~~&{\mathtt {spits(alpaca)}} \nonumber \\
		{\mathtt {fluffiness(X,Y),Y >= 4}} &\Rightarrow  \mathtt {cuddly(X)}. \nonumber \\
		{\mathtt {cuddly(X)}} &\Rightarrow \mathtt {ideal\_pet(X)}. \nonumber \\
		w_1 ~~ {\mathtt {diet(X,carnivore)}} &\Rightarrow {\mathtt {bites(X)}} \nonumber \\
		w_2 ~~ {\mathtt {bites(X)}} &\Rightarrow {\mathtt {cuddly(X)}}  \nonumber \\
		{\mathtt {friends(X,otter)}} &\Rightarrow {\mathtt {ideal\_pet(X)}}. \nonumber \\
	\end{aligned}$$
	\caption[The \gls{mln} translation of the Problog program in Figure~\ref{fig:problog}]{\gls{mln} model for the pet decision problem. \label{fig:mln}}
\end{figure}










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file,
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
